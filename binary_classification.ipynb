{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text, stem=\"None\"):\n",
    "\n",
    "    final_string = \"\"\n",
    "\n",
    "    # Make lower\n",
    "    \n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove line breaks\n",
    "\n",
    "    text = re.sub('\\n', '', text)\n",
    "\n",
    "    # Remove puncuation\n",
    "\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    # Remove stop words\n",
    "\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    useless_words = useless_words + ['hi', 'im']\n",
    "\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "\n",
    "    # Remove numbers\n",
    "\n",
    "    text_filtered = [re.sub('\\w*\\d\\w*', '', w) for w in text_filtered]\n",
    "\n",
    "    ## Remove special chars\n",
    "\n",
    "    text_filtered = [re.sub(r\"[^a-zA-Z0-9 ]\", '', w) for w in text_filtered]\n",
    "\n",
    "    # Stem or Lemmatize\n",
    "\n",
    "    if stem == 'Stem':\n",
    "        stemmer = PorterStemmer() \n",
    "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "    elif stem == 'Lem':\n",
    "        lem = WordNetLemmatizer()\n",
    "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
    "    elif stem == 'Spacy':\n",
    "        text_filtered = nlp(' '.join(text_filtered))\n",
    "        text_stemmed = [y.lemma_ for y in text_filtered]\n",
    "    else:\n",
    "        text_stemmed = text_filtered\n",
    "\n",
    "    final_string = ' '.join(text_stemmed)\n",
    "\n",
    "    final_string = final_string.replace(\"  \", ' ')\n",
    "\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/joshnicholas/article_reccomendation/blob/main/archive/binary_cleaned.csv?raw=true')\n",
    "\n",
    "# columns:\n",
    "# 'status', 'resolved_title', 'resolved_url', 'keywords', 'excerpt',\n",
    "#        'cleaned_text', 'title_word_count', 'word_count'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].astype(str)\n",
    "\n",
    "# Split data into train and test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_text\"], df[\"status\"],test_size=0.2,shuffle=True)\n",
    "\n",
    "# Word2Vec on sentences\n",
    "\n",
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-c41aff178aab>:30: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n"
     ]
    }
   ],
   "source": [
    "#Tf-Idf\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Word2Vec model\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "df['clean_text_tok'] = [nltk.word_tokenize(i) for i in df['cleaned_text']]\n",
    "\n",
    "model = Word2Vec(df['clean_text_tok'],min_count=1)   \n",
    "\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))  \n",
    "\n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "# converting text to numerical data using Word2Vec\n",
    "\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_test_vectors_w2v = modelw.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      3328\n",
      "           1       0.43      0.28      0.34      1509\n",
      "\n",
      "    accuracy                           0.66      4837\n",
      "   macro avg       0.57      0.56      0.55      4837\n",
      "weighted avg       0.63      0.66      0.64      4837\n",
      "\n",
      "Confusion Matrix: [[2766  562]\n",
      " [1086  423]]\n",
      "AUC: 0.607335155732273\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
    "\n",
    "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82      3328\n",
      "           1       0.62      0.08      0.15      1509\n",
      "\n",
      "    accuracy                           0.70      4837\n",
      "   macro avg       0.66      0.53      0.48      4837\n",
      "weighted avg       0.68      0.70      0.61      4837\n",
      "\n",
      "Confusion Matrix: [[3251   77]\n",
      " [1383  126]]\n",
      "AUC: 0.5935954784115818\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression (W2v)\n",
    "\n",
    "lr_w2v=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_w2v.fit(X_train_vectors_w2v, y_train)\n",
    "\n",
    "#Predict y value for test dataset\n",
    "\n",
    "y_predict = lr_w2v.predict(X_test_vectors_w2v)\n",
    "y_prob = lr_w2v.predict_proba(X_test_vectors_w2v)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82      3328\n",
      "           1       0.56      0.01      0.01      1509\n",
      "\n",
      "    accuracy                           0.69      4837\n",
      "   macro avg       0.63      0.50      0.41      4837\n",
      "weighted avg       0.65      0.69      0.56      4837\n",
      "\n",
      "Confusion Matrix: [[3321    7]\n",
      " [1500    9]]\n",
      "AUC: 0.6243402963628486\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(tf-idf)\n",
    "\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_vectors_tfidf, y_train) \n",
    "\n",
    "#Predict y value for test dataset\n",
    "\n",
    "y_predict = nb_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = nb_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  target  predict_prob\n",
      "0  eminem opened restaurant detroit checked detro...       1      0.806617\n",
      "1  teenaged girl periodically transforms giant pa...       1      0.789723\n",
      "2  february   register subscribe save articles later       1      0.506887\n",
      "3  abc grilled anticoalition tweets posted tv per...       1      0.892576\n",
      "4  aussie comedian rental application cancelled r...       1      0.789556\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing the new dataset\n",
    "\n",
    "df['clean_text'] = df['excerpt'].apply(lambda x: clean_string(x)) #preprocess the data\n",
    "\n",
    "X_test= df['clean_text'] \n",
    "\n",
    "#converting words to numerical data using tf-idf\n",
    "\n",
    "X_vector=tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#use the best model to predict 'target' value for the new dataset \n",
    "\n",
    "y_predict = lr_tfidf.predict(X_vector)      \n",
    "y_prob = lr_tfidf.predict_proba(X_vector)[:,1]\n",
    "\n",
    "df['predict_prob'] = y_prob\n",
    "df['target'] = y_predict\n",
    "\n",
    "final = df[['clean_text','target' ,'predict_prob']].reset_index(drop=True)\n",
    "\n",
    "print(final.head())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
